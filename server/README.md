# RAG Chatbot Server

The backend component of the RAG Chatbot, built with FastAPI, LangChain, and Qdrant. Implements RAG (Retrieval-Augmented Generation) for document-based chat.

## Features

- ğŸš€ FastAPI-based REST API
- ğŸ“„ PDF document processing and text extraction
- ğŸ” Vector storage with Qdrant
- ğŸ¤– OpenAI integration for embeddings and chat
- ğŸ”„ Asynchronous request handling
- ğŸ“Š RAG implementation with LangChain
- ğŸ”’ Environment-based configuration

## Prerequisites

- Python 3.13
- Poetry
- OpenAI API Key
- Docker (optional)

## Configuration

Environment variables (in `app/.env`):
```bash
# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here
```

## Installation

### Using Docker (Recommended)

The server is part of the main docker-compose setup. See root README for instructions.

### Manual Installation

1. Install Poetry:
   ```bash
   pip install poetry
   ```

2. Install dependencies:
   ```bash
   poetry install
   ```

3. Run the application:
   ```bash
   poetry run uvicorn app.main:app --reload
   ```

## Project Structure

```
server/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/         # RAG and chat agent implementations
â”‚   â”œâ”€â”€ databases/      # Database connections (Qdrant)
â”‚   â”œâ”€â”€ routers/        # API route handlers
â”‚   â”œâ”€â”€ schemas/        # Pydantic schemas
â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â”œâ”€â”€ utils/          # Helper functions and utilities
â”‚   â”œâ”€â”€ .env           # Environment configuration
â”‚   â”œâ”€â”€ .env.example   # Example environment file
â”‚   â”œâ”€â”€ main.py        # Application entry point
â”‚   â””â”€â”€ settings.py    # App settings and configuration
â”œâ”€â”€ Dockerfile         # Docker configuration
â”œâ”€â”€ pyproject.toml     # Poetry dependencies
â””â”€â”€ poetry.lock       # Poetry lock file
```

## API Documentation

### Endpoints

#### Files API
- `POST /files/upload`
  - Upload and process PDF files
  - Request: Multipart form data with PDF files
  - Response: Processing status for each file
  ```json
  {
    "message": "Processed 2 files successfully, 0 failed",
    "successful": [
      {"filename": "doc1.pdf", "status": "success"}
    ],
    "failed": []
  }
  ```

#### Chat API
- `POST /chat/`
  - Send a message to the chatbot
  - Request:
    ```json
    {
      "messages": [
        {"content": "What's in the documents?", "sender": "user"}
      ]
    }
    ```
  - Response:
    ```json
    {
      "response": "Based on the documents..."
    }
    ```

Full OpenAPI documentation available at `/docs` when server is running.

## Components

### Document Processing
- PDF text extraction
- Text chunking and preprocessing
- Vector embedding generation
- Storage in Qdrant vector database

### RAG Implementation
- Semantic search in vector store
- Context retrieval
- OpenAI chat completion
- Response generation

### Vector Store
- Persistent Qdrant storage
- Efficient similarity search
- Document metadata management

## Development

1. Set up Poetry environment:
   ```bash
   poetry install
   ```

2. Run with hot-reload:
   ```bash
   poetry run uvicorn app.main:app --reload
   ```

3. Access the API at http://localhost:8000

## Testing

Run tests with Poetry:
```bash
poetry run pytest
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## License

[MIT License](../LICENSE)
